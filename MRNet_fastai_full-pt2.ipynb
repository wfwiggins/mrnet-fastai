{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m..\u001b[00m\n",
      "├── \u001b[01;34mdata\u001b[00m\n",
      "│   ├── \u001b[01;34maxial\u001b[00m\n",
      "│   │   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   │   └── \u001b[01;34mvalid\u001b[00m\n",
      "│   ├── \u001b[01;34mcoronal\u001b[00m\n",
      "│   │   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   │   └── \u001b[01;34mvalid\u001b[00m\n",
      "│   └── \u001b[01;34msagittal\u001b[00m\n",
      "│       ├── \u001b[01;34mmodels\u001b[00m\n",
      "│       ├── \u001b[01;34mtrain\u001b[00m\n",
      "│       └── \u001b[01;34mvalid\u001b[00m\n",
      "└── \u001b[01;34mmrnet-fastai\u001b[00m\n",
      "    └── \u001b[01;34mexp\u001b[00m\n",
      "\n",
      "13 directories\n"
     ]
    }
   ],
   "source": [
    "! tree -d .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_abnl.pkl\t MRNet_EDA.ipynb\t      notebook2script.py\r\n",
      "exp\t\t MRNet_fastai_full.ipynb      README.md\r\n",
      "exports.ipynb\t MRNet_fastai_full-pt2.ipynb  slice_stats.json\r\n",
      "LICENSE\t\t MRNet_fastai_toy.ipynb       train_cases.pkl\r\n",
      "loss_weights.pt  MRNet_pixel-distrib.ipynb    train_pix_distr.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axial\t  train-abnormal.csv  valid-abnormal.csv\r\n",
      "coronal   train-acl.csv       valid-acl.csv\r\n",
      "sagittal  train-meniscus.csv  valid-meniscus.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "data_path = Path('../data')\n",
    "sag_path = data_path/'sagittal'\n",
    "cor_path = data_path/'coronal'\n",
    "ax_path = data_path/'axial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substantial class imbalance for the normal/abnormal task\n",
    "\n",
    "Given this, we'll derive weights for a weighted binary cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1130, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case  Abnormal\n",
       "0  0000         1\n",
       "1  0001         1\n",
       "2  0002         1\n",
       "3  0003         1\n",
       "4  0004         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_abnl = pd.read_csv(data_path/'train-abnormal.csv', header=None,\n",
    "                       names=['Case', 'Abnormal'], \n",
    "                       dtype={'Case': str, 'Abnormal': np.int64})\n",
    "print(train_abnl.shape)\n",
    "train_abnl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8079646017699115\n",
      "[0.8079646017699115, 0.19203539823008853]\n"
     ]
    }
   ],
   "source": [
    "w = train_abnl.Abnormal.sum() / train_abnl.shape[0]\n",
    "print(w)\n",
    "weights = [w, 1-w]\n",
    "print(weights)\n",
    "# torch.save(weights, 'loss_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "weights = torch.load('loss_weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously created files\n",
    "\n",
    "- `df_abnl` -> master `df` for use with Data Block API, also contains # of slices per series\n",
    "- `slice_stats` -> `dict` stored as `json` with mean and max # of slices per series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Abnormal</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>coronal_slices</th>\n",
       "      <th>sagittal_slices</th>\n",
       "      <th>axial_slices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/0002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/0003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/0004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Case  Abnormal  is_valid  coronal_slices  sagittal_slices  \\\n",
       "0  train/0000         1         0              25               27   \n",
       "1  train/0001         1         0              22               23   \n",
       "2  train/0002         1         0              24               24   \n",
       "3  train/0003         1         0              22               21   \n",
       "4  train/0004         1         0              30               30   \n",
       "\n",
       "   axial_slices  \n",
       "0            25  \n",
       "1            28  \n",
       "2            24  \n",
       "3            25  \n",
       "4            31  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abnl = pd.read_pickle('df_abnl.pkl')\n",
    "df_abnl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coronal': {'mean': 29.6416, 'max': 57},\n",
       " 'sagittal': {'mean': 30.3776, 'max': 51},\n",
       " 'axial': {'mean': 34.2032, 'max': 61}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('slice_stats.json', 'r') as file:\n",
    "    stats = json.load(file)\n",
    "    \n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "max_slc = stats['sagittal']['max']\n",
    "print(max_slc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRNet implementation\n",
    "\n",
    "Modified from the original [paper](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699) to (sort of) work with `fastai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MRNet(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.base = models.alexnet(pretrained=pretrained)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = torch.squeeze(x, dim=0)\n",
    "        x = self.base.features(x)\n",
    "        x = self.gap(x).view(x.size(0), -1)\n",
    "        x = torch.max(x, 0, keepdim=True)[0]\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted binary cross entropy loss\n",
    "\n",
    "Custom function, subclassed from `nn.Module`, to handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WtBCELoss(nn.Module):\n",
    "    def __init__(self, wts):\n",
    "        super().__init__()\n",
    "        self.wts = wts\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        loss = self.wts[0]*(target.float() * torch.log(output)) + self.wts[1]*(\n",
    "                            (1-target).float() * torch.log(1-output))\n",
    "        return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom data classes\n",
    "\n",
    "- `MR3DImDataBunch` -> `ImageDataBunch` subclass with modified `one_batch` method to squeeze batches (MRNet only supports batch size of 1\n",
    "- `MR3DImageList` -> `ImageList` subclass redesigned to load full image stacks from one plane/sequence and convert from `np.ndarray` to `fastai.vision` `Image` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MR3DImDataBunch(ImageDataBunch):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def one_batch(self, ds_type:DatasetType=DatasetType.Train, detach:bool=True, denorm:bool=True, cpu:bool=True)->Collection[Tensor]:\n",
    "        \"Get one batch from the data loader of `ds_type`. Optionally `detach` and `denorm`.\"\n",
    "        dl = self.dl(ds_type)\n",
    "        w = self.num_workers\n",
    "        self.num_workers = 0\n",
    "        try:     x,y = next(iter(dl))\n",
    "        finally: self.num_workers = w\n",
    "        if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)\n",
    "        norm = getattr(self,'norm',False)\n",
    "        if denorm and norm:\n",
    "            x = self.denorm(x)\n",
    "            if norm.keywords.get('do_y',False): y = self.denorm(y, do_x=True)\n",
    "        x = torch.squeeze(x, dim=0) # fingers crossed, this will do the trick\n",
    "        return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MR3DImageList(ImageList):\n",
    "    _bunch = MR3DImDataBunch\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "#         self.max_slc = 51\n",
    "        self.c = 1\n",
    "        \n",
    "    def open(self, fn):\n",
    "        x = np.load(fn)\n",
    "#         if x.shape[0] < self.max_slc:\n",
    "#             x_pad = np.zeros((self.max_slc, 256, 256))\n",
    "#             mid = x_pad.shape[0] // 2\n",
    "#             up = x.shape[0] // 2\n",
    "#             if x.shape[0] % 2 == 1: x_pad[mid-up:mid+up+1] = x\n",
    "#             else: x_pad[mid-up:mid+up] = x\n",
    "#         else:\n",
    "#             x_pad = x\n",
    "        return self.arr2image(np.stack([x]*3, axis=1)) # change back to x_pad if doesn't work\n",
    "    \n",
    "    @staticmethod\n",
    "    def arr2image(arr:np.ndarray, div:bool=True, cls:type=Image):\n",
    "        x = Tensor(arr)\n",
    "        if div == True: x.div_(255)\n",
    "        return cls(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Callback\n",
    "\n",
    "Squeezes input batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MRNetCallback(Callback):\n",
    "    def on_batch_begin(self, last_input, **kwargs):\n",
    "        x = torch.squeeze(last_input, dim=0)\n",
    "        return dict(last_input=x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interim Summary\n",
    "\n",
    "Thus far, all of the above classes/methods seem to be working well. But we still need a custom `Learner` with setup function (a la `cnn_learner`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrnet_learner(data:DataBunch, model:Callable=MRNet(), pretrained:bool=True, init=nn.init.kaiming_normal_,\n",
    "                  **kwargs:Any)->Learner:\n",
    "    learn = Learner(data, model, **kwargs)\n",
    "    if pretrained: learn.freeze()\n",
    "#     if init: apply_init(model[1], init)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = MR3DImageList.from_df(df_abnl, sag_path, suffix='.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sagittal/train/0000.npy'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il.items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MR3DImageList (1250 items)\n",
       "Image (36, 3, 256, 256),Image (26, 3, 256, 256),Image (32, 3, 256, 256),Image (30, 3, 256, 256),Image (32, 3, 256, 256)\n",
       "Path: ../data/sagittal"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemLists;\n",
       "\n",
       "Train: MR3DImageList (1130 items)\n",
       "Image (36, 3, 256, 256),Image (26, 3, 256, 256),Image (32, 3, 256, 256),Image (30, 3, 256, 256),Image (32, 3, 256, 256)\n",
       "Path: ../data/sagittal;\n",
       "\n",
       "Valid: MR3DImageList (120 items)\n",
       "Image (27, 3, 256, 256),Image (23, 3, 256, 256),Image (24, 3, 256, 256),Image (21, 3, 256, 256),Image (30, 3, 256, 256)\n",
       "Path: ../data/sagittal;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = il.split_from_df(col=2)\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelLists;\n",
       "\n",
       "Train: LabelList (1130 items)\n",
       "x: MR3DImageList\n",
       "Image (36, 3, 256, 256),Image (26, 3, 256, 256),Image (32, 3, 256, 256),Image (30, 3, 256, 256),Image (32, 3, 256, 256)\n",
       "y: CategoryList\n",
       "1,1,1,1,1\n",
       "Path: ../data/sagittal;\n",
       "\n",
       "Valid: LabelList (120 items)\n",
       "x: MR3DImageList\n",
       "Image (27, 3, 256, 256),Image (23, 3, 256, 256),Image (24, 3, 256, 256),Image (21, 3, 256, 256),Image (30, 3, 256, 256)\n",
       "y: CategoryList\n",
       "0,0,0,0,0\n",
       "Path: ../data/sagittal;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = sd.label_from_df(cols=1)\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "data = ll.databunch(bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b5ad455946e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m learn = mrnet_learner(data, MRNet(), opt_func=optim.Adam, loss_func=WtBCELoss(weights),\n\u001b[0;32m----> 2\u001b[0;31m                       callbacks=MRNetCallback(), metrics=accuracy)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-e32bc3fa5af9>\u001b[0m in \u001b[0;36mmrnet_learner\u001b[0;34m(data, model, pretrained, init, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m                   **kwargs:Any)->Learner:\n\u001b[1;32m      3\u001b[0m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     if init: apply_init(model[1], init)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfreeze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"Freeze up to last layer group.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn = mrnet_learner(data, MRNet(), opt_func=optim.Adam, loss_func=WtBCELoss(weights),\n",
    "                      callbacks=MRNetCallback(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MRNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MRNet(\n",
       "  (base): AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Dropout(p=0.5)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking up where we left off in the previous notebook...\n",
    "\n",
    "We need a new `Learner` to enable splitting and freezing of our custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "layer_groups = [model.base.features, model.base.avgpool, model.base.classifier, \n",
    "                model.gap, model.classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MRNetLearner(Learner):\n",
    "    def freeze_to(self, n:int)->None:\n",
    "        \"Freeze layers up to layer group `n`.\"\n",
    "        for g in self.layer_groups[:n]:\n",
    "            print(g)\n",
    "            if is_listy(g):\n",
    "                for l in g:\n",
    "                    print(l)\n",
    "                    if not self.train_bn or not isinstance(l, bn_types): requires_grad(l, False)\n",
    "            else: requires_grad(g, False)    \n",
    "        for g in self.layer_groups[n:]: \n",
    "            print(g)\n",
    "            requires_grad(g, True)\n",
    "        self.create_opt(defaults.lr)\n",
    "\n",
    "    def freeze(self)->None:\n",
    "        \"Freeze up to the 2nd to last layer group (i.e. gap).\"\n",
    "        self.freeze_to(-1)\n",
    "        self.create_opt(defaults.lr)\n",
    "\n",
    "    def unfreeze(self):\n",
    "        \"Unfreeze entire model.\"\n",
    "        self.freeze_to(0)\n",
    "        self.create_opt(defaults.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mrnet_learner(data:DataBunch, model:Callable=MRNet(), pretrained:bool=True, init=nn.init.kaiming_normal_,\n",
    "                  **kwargs:Any)->Learner:\n",
    "    _layer_groups = [model.base.features, model.base.avgpool, model.base.classifier, \n",
    "                model.gap, model.classifier]\n",
    "    learn = MRNetLearner(data, model, layer_groups=_layer_groups, **kwargs)\n",
    "    if pretrained: learn.freeze()\n",
    "    if init: apply_init(model.classifier, init)\n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU(inplace)\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace)\n",
      "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.5)\n",
      "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Dropout(p=0.5)\n",
      "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=1)\n",
      "Linear(in_features=256, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "learn = mrnet_learner(data, MRNet(), opt_func=optim.Adam, loss_func=WtBCELoss(weights),\n",
    "                      callbacks=MRNetCallback(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Conv2d               [64, 63, 63]         23,296     False     \n",
       "______________________________________________________________________\n",
       "ReLU                 [64, 63, 63]         0          False     \n",
       "______________________________________________________________________\n",
       "MaxPool2d            [64, 31, 31]         0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [192, 31, 31]        307,392    False     \n",
       "______________________________________________________________________\n",
       "ReLU                 [192, 31, 31]        0          False     \n",
       "______________________________________________________________________\n",
       "MaxPool2d            [192, 15, 15]        0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [384, 15, 15]        663,936    False     \n",
       "______________________________________________________________________\n",
       "ReLU                 [384, 15, 15]        0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 15, 15]        884,992    False     \n",
       "______________________________________________________________________\n",
       "ReLU                 [256, 15, 15]        0          False     \n",
       "______________________________________________________________________\n",
       "Conv2d               [256, 15, 15]        590,080    False     \n",
       "______________________________________________________________________\n",
       "ReLU                 [256, 15, 15]        0          False     \n",
       "______________________________________________________________________\n",
       "MaxPool2d            [256, 7, 7]          0          False     \n",
       "______________________________________________________________________\n",
       "AdaptiveAvgPool2d    [256, 1, 1]          0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1]                  257        True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 2,469,953\n",
       "Total trainable params: 257\n",
       "Total non-trainable params: 2,469,696"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='165' class='' max='1130', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.60% [165/1130 00:07<00:42 nan]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, slice(1e-03, 1e-02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MRNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MRNet(\n",
       "  (base): AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Dropout(p=0.5)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = learn.data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 3, 256, 256])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1490]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "output = model.forward(xb)\n",
    "output = Variable(output)\n",
    "print(output)\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "target = yb\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5385)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = WtBCELoss(weights)\n",
    "loss = loss_fn.forward(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([1])) must be the same as input size (torch.Size([1, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-bb4d60c03e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1])) must be the same as input size (torch.Size([1, 1]))"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "wts = torch.FloatTensor(weights)\n",
    "wts = wts.cuda()\n",
    "loss = F.binary_cross_entropy_with_logits(Variable(output), Variable(target), weight=Variable(wts))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted MRNet_fastai_full-pt2.ipynb to exp/nb_MRNet.py\r\n"
     ]
    }
   ],
   "source": [
    "! python notebook2script.py MRNet_fastai_full-pt2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
